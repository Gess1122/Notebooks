{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73032d99-37c7-4f36-b91e-2e4665b12048",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: apache-sedona in c:\\users\\pc\\anaconda3\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: attrs in c:\\users\\pc\\anaconda3\\lib\\site-packages (from apache-sedona) (23.1.0)\n",
      "Requirement already satisfied: shapely>=1.7.0 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from apache-sedona) (2.1.0)\n",
      "Requirement already satisfied: numpy>=1.21 in c:\\users\\pc\\anaconda3\\lib\\site-packages (from shapely>=1.7.0->apache-sedona) (1.26.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install --upgrade apache-sedona"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9decbcf8-d971-4812-8716-11b7023856e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\pc\\AppData\\Local\\Temp\\ipykernel_12744\\507244897.py:14: DeprecationWarning: Call to deprecated function registerAll (Deprecated since 1.4.1, use SedonaContext.create() instead.).\n",
      "  SedonaRegistrator.registerAll(spark)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spark version: 3.5.4\n",
      "Scala version JVM: version 2.12.18\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from sedona.register import SedonaRegistrator\n",
    "from sedona.utils import KryoSerializer, SedonaKryoRegistrator\n",
    "\n",
    "# Creation de la session Spark avec Sedona\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"SedonaApp\") \\\n",
    "    .config(\"spark.serializer\", \"org.apache.spark.serializer.KryoSerializer\") \\\n",
    "    .config(\"spark.kryo.registrator\", \"org.apache.sedona.core.serde.SedonaKryoRegistrator\") \\\n",
    "    .config(\"spark.jars.packages\", \"org.apache.sedona:sedona-spark-shaded-3.5_2.12:1.7.2,org.datasyslab:geotools-wrapper:1.4.0-28.2\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "SedonaRegistrator.registerAll(spark)\n",
    "\n",
    "# Affichage des versions\n",
    "print(f\"Spark version: {spark.version}\")\n",
    "print(\"Scala version JVM:\", spark.sparkContext._jvm.scala.util.Properties.versionString())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb48eda-9003-4968-996b-31710bf90184",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.csv(\"Accident.csv\", header=True, inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d402f7e9-a904-428d-8a5f-c6bff395d005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Quarter: string (nullable = true)\n",
      " |-- State: string (nullable = true)\n",
      " |-- Total_Crashes: integer (nullable = true)\n",
      " |-- Num_Injured: integer (nullable = true)\n",
      " |-- Num_Killed: integer (nullable = true)\n",
      " |-- Total_Vehicles_Involved: integer (nullable = true)\n",
      " |-- SPV: integer (nullable = true)\n",
      " |-- DAD: integer (nullable = true)\n",
      " |-- PWR: integer (nullable = true)\n",
      " |-- FTQ: integer (nullable = true)\n",
      " |-- Other_Factors: integer (nullable = true)\n",
      " |-- Latitude: double (nullable = true)\n",
      " |-- Longitude: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06fb959d-bfab-4dac-8c6a-d9ff2a0b3cef",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import expr\n",
    "\n",
    "df_geo = df.withColumn(\n",
    "    \"geom\",\n",
    "    expr(\"ST_Point(cast(Longitude as Decimal(24,20)), cast(Latitude as Decimal(24,20)))\")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0d1a40c4-9eca-4c8d-b094-547cbf475a1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "df_with_id = df_geo.withColumn(\"id\", monotonically_increasing_id())\n",
    "df_with_id.createOrReplaceTempView(\"accidents_geom\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a985f93-8e38-48b0-80da-cdab58c32ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Crrer une vue\n",
    "df_geo.createOrReplaceTempView(\"accidents\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "30f41f65-eca9-44bd-8a85-f3e18874971c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "\n",
    "df_geo = df_geo.withColumn(\"id\", monotonically_increasing_id())\n",
    "df_geo.createOrReplaceTempView(\"accidents_geom\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e688ec-e399-42f5-91b0-8d9bf1489723",
   "metadata": {},
   "source": [
    "### Les lieux où plusieurs accidents sont géographiquement très proches les uns des autres (Analyse de proximité / regroupement spatial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "da26b255-8bf0-42b7-9fbf-5881f562c03f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+-------+----------+----------+------+-------+\n",
      "|State      |Quarter|Latitude  |Longitude |Deaths|Injured|\n",
      "+-----------+-------+----------+----------+------+-------+\n",
      "|Cross River|Q2 2021|5.8671966 |8.5204774 |5     |74     |\n",
      "|Gombe      |Q2 2022|10.4304018|11.2065408|35    |199    |\n",
      "|Benue      |Q4 2022|7.3505747 |8.7772877 |24    |225    |\n",
      "|Delta      |Q3 2021|5.5273061 |6.1784167 |23    |122    |\n",
      "|Benue      |Q2 2022|7.3505747 |8.7772877 |51    |273    |\n",
      "|Oyo        |Q1 2024|8.2151249 |3.5642897 |68    |298    |\n",
      "|Plateau    |Q2 2021|9.0583446 |9.6826289 |23    |283    |\n",
      "|Oyo        |Q1 2022|8.2151249 |3.5642897 |73    |540    |\n",
      "|Jigawa     |Q2 2022|12.3252362|9.5103296 |46    |333    |\n",
      "|Kwara      |Q2 2022|8.8367891 |4.6688487 |67    |342    |\n",
      "|Akwa Ibom  |Q1 2024|4.9906379 |7.7966205 |5     |23     |\n",
      "|Plateau    |Q1 2024|9.0583446 |9.6826289 |15    |185    |\n",
      "|Delta      |Q1 2021|5.5273061 |6.1784167 |51    |196    |\n",
      "|Kaduna     |Q4 2023|10.5182899|7.4359863 |150   |889    |\n",
      "|Gombe      |Q1 2021|10.4304018|11.2065408|31    |232    |\n",
      "|Taraba     |Q4 2023|8.0141334 |10.7376336|13    |113    |\n",
      "|Gombe      |Q3 2022|10.4304018|11.2065408|9     |165    |\n",
      "|Yobe       |Q3 2022|12.1233242|11.5065937|60    |191    |\n",
      "|Abia       |Q4 2022|5.4540953 |7.5153071 |7     |89     |\n",
      "|Lagos      |Q1 2023|6.4550575 |3.3941795 |40    |230    |\n",
      "+-----------+-------+----------+----------+------+-------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_clusters = \"\"\"\n",
    "SELECT DISTINCT\n",
    "    a1.State AS State,\n",
    "    a1.Quarter AS Quarter,\n",
    "    a1.Latitude AS Latitude,\n",
    "    a1.Longitude AS Longitude,\n",
    "    a1.Num_Killed AS Deaths,\n",
    "    a1.Num_Injured AS Injured\n",
    "FROM accidents_geom a1\n",
    "JOIN accidents_geom a2\n",
    "  ON a1.id != a2.id\n",
    "WHERE ST_Intersects(\n",
    "    ST_Buffer(a1.geom, 0.05),\n",
    "    a2.geom\n",
    ")\n",
    "\"\"\"\n",
    "\n",
    "df_clusters = spark.sql(query_clusters)\n",
    "df_clusters.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71fd558b-bea2-49e9-82b1-ead30e0c7d73",
   "metadata": {},
   "source": [
    "La requête identifie les lieux où plusieurs accidents sont géographiquement très proches les uns des autres (dans un rayon d’environ 5 km). Cela peut signaler :\n",
    "\n",
    "Un point noir routier (zone à haut risque).\n",
    "\n",
    "Une mauvaise infrastructure (routes étroites, feux absents, etc.).\n",
    "\n",
    "Un problème de signalisation ou d’éclairage.\n",
    "\n",
    "Une concentration de population et de trafic (zones urbaines)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df164985-2495-4036-946f-1cf0c224b232",
   "metadata": {},
   "source": [
    "### Identifier les zones avec un taux de mortalite elever pour orienter les autorites (Agrégation spatiale)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "e08e3f5a-6937-48f3-8c44-2e403c49772a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------+-----------+--------------+\n",
      "|lat_bin|lon_bin|nb_accidents|total_morts|taux_mortalite|\n",
      "+-------+-------+------------+-----------+--------------+\n",
      "|8.0    |3.5    |1           |45         |45.0          |\n",
      "|9.5    |5.5    |1           |41         |41.0          |\n",
      "|7.0    |5.0    |8           |319        |39.88         |\n",
      "|10.5   |10.0   |4           |153        |38.25         |\n",
      "|12.0   |9.5    |10          |378        |37.8          |\n",
      "|9.0    |7.0    |1           |37         |37.0          |\n",
      "|11.5   |8.5    |4           |140        |35.0          |\n",
      "|7.5    |6.5    |3           |103        |34.33         |\n",
      "|6.0    |3.0    |12          |409        |34.08         |\n",
      "|8.0    |8.0    |5           |166        |33.2          |\n",
      "|7.5    |4.0    |8           |262        |32.75         |\n",
      "|12.5   |7.5    |13          |404        |31.08         |\n",
      "|6.5    |5.5    |11          |338        |30.73         |\n",
      "|8.5    |4.5    |3           |88         |29.33         |\n",
      "|12.0   |11.5   |11          |302        |27.45         |\n",
      "|10.0   |11.0   |14          |375        |26.79         |\n",
      "|13.0   |5.0    |13          |347        |26.69         |\n",
      "|6.0    |7.5    |14          |369        |26.36         |\n",
      "|5.5    |6.0    |12          |305        |25.42         |\n",
      "|9.0    |9.5    |13          |330        |25.38         |\n",
      "+-------+-------+------------+-----------+--------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query_mortalite_spatiale = \"\"\"\n",
    "SELECT\n",
    "  FLOOR(Latitude * 2) / 2 AS lat_bin,\n",
    "  FLOOR(Longitude * 2) / 2 AS lon_bin,\n",
    "  COUNT(*) AS nb_accidents,\n",
    "  SUM(Num_Killed) AS total_morts,\n",
    "  ROUND(SUM(Num_Killed) / COUNT(*), 2) AS taux_mortalite\n",
    "FROM accidents\n",
    "WHERE Num_Killed IS NOT NULL AND Num_Killed < 50\n",
    "GROUP BY lat_bin, lon_bin\n",
    "ORDER BY taux_mortalite DESC\n",
    "\"\"\"\n",
    "df_mortalite_spatiale = spark.sql(query_mortalite_spatiale)\n",
    "df_mortalite_spatiale.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48b1b61d-f72b-4410-bd1d-f0ecdf0f83fa",
   "metadata": {},
   "source": [
    "L’analyse spatiale du taux de mortalité routière par cellule géographique (définie par des tranches de 0.5° de latitude et de longitude) permet de localiser les zones les plus critiques. Par exemple, la cellule (8.0, 3.5) présente un taux de mortalité de 45 décès pour un seul accident, ce qui indique une extrême gravité. D'autres zones comme (7.0, 5.0) ou (12.0, 9.5) enregistrent également des taux élevés, révélant des points noirs potentiels en matière de sécurité routière. Ce type d’analyse aide à orienter les autorités vers des zones prioritaires d’intervention, afin de renforcer la prévention et les infrastructures routières."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a505aa69-5db1-45a2-a184-d0fe5bf954e4",
   "metadata": {},
   "source": [
    "### Comparaison Urbain (Lagos) vs Rurale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fa8d9169-7bca-456e-9750-238f3e1948a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+----------------+-----+-------+\n",
      "|                Zone|Nombre_Accidents|Morts|Blesses|\n",
      "+--------------------+----------------+-----+-------+\n",
      "|         Zone rurale|             504|20513| 124203|\n",
      "|Zone urbaine (Lagos)|              14|  518|   3034|\n",
      "+--------------------+----------------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query6 = \"\"\"\n",
    "SELECT\n",
    "    CASE\n",
    "        WHEN ST_Within(geom, ST_GeomFromText('POLYGON((3.2 6.3, 3.2 6.7, 3.6 6.7, 3.6 6.3, 3.2 6.3))'))\n",
    "        THEN 'Zone urbaine (Lagos)'\n",
    "        ELSE 'Zone rurale'\n",
    "    END AS Zone,\n",
    "    COUNT(*) AS Nombre_Accidents,\n",
    "    SUM(Num_Killed) AS Morts,\n",
    "    SUM(Num_Injured) AS Blesses\n",
    "FROM accidents_geom\n",
    "GROUP BY Zone\n",
    "\"\"\"\n",
    "df_zones = spark.sql(query6)\n",
    "df_zones.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71167a7-9722-4036-84be-35043190bb47",
   "metadata": {},
   "source": [
    "### Gravité moyenne par État (morts/accident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a5d75467-1412-4ee5-a7cd-50b7de8e47ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+--------------------+\n",
      "|   State|Morts_par_Accident|Blesses_par_Accident|\n",
      "+--------+------------------+--------------------+\n",
      "|  Kaduna|            160.14|              804.57|\n",
      "|    Ogun|             100.0|              622.36|\n",
      "|   Niger|             96.86|              509.43|\n",
      "|  Bauchi|              82.5|              492.07|\n",
      "|     FCT|             77.64|              628.93|\n",
      "|     Oyo|              75.0|              392.57|\n",
      "|    Kano|             74.14|              320.57|\n",
      "|    Kogi|             64.14|              370.29|\n",
      "|   Kwara|              58.0|              307.14|\n",
      "|Nasarawa|             53.21|              528.64|\n",
      "|    Ondo|             48.79|              271.14|\n",
      "|    Osun|             47.21|              295.64|\n",
      "|  Jigawa|             44.43|               380.5|\n",
      "|   Lagos|              37.0|              216.71|\n",
      "|     Edo|             35.21|              149.86|\n",
      "|    Yobe|             34.64|               229.0|\n",
      "| Katsina|             34.36|              152.64|\n",
      "|   Kebbi|             32.29|              164.64|\n",
      "|   Delta|             29.86|              139.43|\n",
      "|  Sokoto|             29.64|              106.14|\n",
      "+--------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query10 = \"\"\"\n",
    "SELECT\n",
    "    State,\n",
    "    ROUND(SUM(Num_Killed) / COUNT(*), 2) AS Morts_par_Accident,\n",
    "    ROUND(SUM(Num_Injured) / COUNT(*), 2) AS Blesses_par_Accident\n",
    "FROM accidents_geom\n",
    "GROUP BY State\n",
    "ORDER BY Morts_par_Accident DESC\n",
    "\"\"\"\n",
    "df_gravite = spark.sql(query10)\n",
    "df_gravite.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd8f3c50-0a8d-4e67-a575-eacf4addfb26",
   "metadata": {},
   "source": [
    "Cette analyse met en évidence la gravité moyenne des accidents dans chaque État nigérian, en calculant le nombre moyen de morts et de blessés par accident. Des États comme Kaduna, Ogun et Niger présentent des taux exceptionnellement élevés, suggérant des accidents très graves . Lagos, bien que très accidentogène, affiche une gravité moyenne plus faible, ce qui pourrait refléter une meilleure prise en charge. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e2db95a-e3aa-4ae6-8796-4586738546ec",
   "metadata": {},
   "source": [
    "### Regroupement spatial (Clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "ce37c825-88db-4b1a-8932-8a8bbbd8f90d",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "[UNRESOLVED_ROUTINE] Cannot resolve function `ST_Pixelize` on search path [`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`].; line 4 pos 9",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[69], line 11\u001b[0m\n\u001b[0;32m      1\u001b[0m query \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;124mSELECT grid_cell, COUNT(*) AS nb_accidents\u001b[39m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124mFROM (\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;124mORDER BY nb_accidents DESC\u001b[39m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;124m\"\"\"\u001b[39m\n\u001b[1;32m---> 11\u001b[0m df_pix \u001b[38;5;241m=\u001b[39m spark\u001b[38;5;241m.\u001b[39msql(query)\n\u001b[0;32m     12\u001b[0m df_pix\u001b[38;5;241m.\u001b[39mshow(truncate\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\sql\\session.py:1631\u001b[0m, in \u001b[0;36mSparkSession.sql\u001b[1;34m(self, sqlQuery, args, **kwargs)\u001b[0m\n\u001b[0;32m   1627\u001b[0m         \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1628\u001b[0m         litArgs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jvm\u001b[38;5;241m.\u001b[39mPythonUtils\u001b[38;5;241m.\u001b[39mtoArray(\n\u001b[0;32m   1629\u001b[0m             [_to_java_column(lit(v)) \u001b[38;5;28;01mfor\u001b[39;00m v \u001b[38;5;129;01min\u001b[39;00m (args \u001b[38;5;129;01mor\u001b[39;00m [])]\n\u001b[0;32m   1630\u001b[0m         )\n\u001b[1;32m-> 1631\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jsparkSession\u001b[38;5;241m.\u001b[39msql(sqlQuery, litArgs), \u001b[38;5;28mself\u001b[39m)\n\u001b[0;32m   1632\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1633\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(kwargs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\py4j\\java_gateway.py:1322\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[1;34m(self, *args)\u001b[0m\n\u001b[0;32m   1316\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1317\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1318\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[0;32m   1319\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[0;32m   1321\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[1;32m-> 1322\u001b[0m return_value \u001b[38;5;241m=\u001b[39m get_return_value(\n\u001b[0;32m   1323\u001b[0m     answer, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtarget_id, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mname)\n\u001b[0;32m   1325\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[0;32m   1326\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(temp_arg, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_detach\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pyspark\\errors\\exceptions\\captured.py:185\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[1;34m(*a, **kw)\u001b[0m\n\u001b[0;32m    181\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[0;32m    182\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[0;32m    183\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[0;32m    184\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[1;32m--> 185\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    186\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    187\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mAnalysisException\u001b[0m: [UNRESOLVED_ROUTINE] Cannot resolve function `ST_Pixelize` on search path [`system`.`builtin`, `system`.`session`, `spark_catalog`.`default`].; line 4 pos 9"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT grid_cell, COUNT(*) AS nb_accidents\n",
    "FROM (\n",
    "  SELECT ST_Pixelize(geom, 0.1) AS grid_cell\n",
    "  FROM accidents\n",
    ")\n",
    "GROUP BY grid_cell\n",
    "ORDER BY nb_accidents DESC\n",
    "\"\"\"\n",
    "\n",
    "df_pix = spark.sql(query)\n",
    "df_pix.show(truncate=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b1e5dc5-54a6-463d-8718-ce36c0fca2fe",
   "metadata": {},
   "source": [
    "#### les zones les plus accidentogenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "fbbd94a9-c5db-42b5-8cd5-e317b764d57f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+-----------+----------------+-----+-------+\n",
      "|lat_bin|lon_bin|      State|nombre_accidents|morts|blesses|\n",
      "+-------+-------+-----------+----------------+-----+-------+\n",
      "|    6.6|   5.97|        Edo|              14|  493|   2098|\n",
      "|  12.56|   7.62|    Katsina|              14|  481|   2137|\n",
      "|   4.76|   6.02|    Bayelsa|              14|   57|    299|\n",
      "|   6.19|   8.03|     Ebonyi|              14|  265|   1237|\n",
      "|  10.43|   11.2|      Gombe|              14|  375|   3590|\n",
      "|   7.02|   5.05|       Ondo|              14|  683|   3796|\n",
      "|  10.51|   7.43|     Kaduna|              14| 2242|  11264|\n",
      "|   5.86|   8.52|Cross River|              14|  217|   1025|\n",
      "|   6.45|   3.39|      Lagos|              14|  518|   3034|\n",
      "|  12.18|   13.3|      Borno|              14|  219|   1638|\n",
      "+-------+-------+-----------+----------------+-----+-------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query = \"\"\"\n",
    "SELECT \n",
    "    FLOOR(Latitude * 100) / 100 AS lat_bin,\n",
    "    FLOOR(Longitude * 100) / 100 AS lon_bin,\n",
    "    State,\n",
    "    COUNT(*) AS nombre_accidents,\n",
    "    SUM(Num_Killed) AS morts,\n",
    "    SUM(Num_Injured) AS blesses\n",
    "FROM accidents\n",
    "GROUP BY lat_bin, lon_bin, state\n",
    "ORDER BY nombre_accidents DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result = spark.sql(query)\n",
    "result.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "67a61b76-2d46-413f-ba1d-5961b878b7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+-------+------------------------+\n",
      "|lat_bin|lon_bin|nb_accidents_dans_buffer|\n",
      "+-------+-------+------------------------+\n",
      "|   5.45|   7.51|                      14|\n",
      "|    6.6|   5.97|                      14|\n",
      "|   8.21|   3.56|                      14|\n",
      "|   8.01|  10.73|                      14|\n",
      "|   4.76|   6.02|                      14|\n",
      "|   9.05|   9.68|                      14|\n",
      "|   5.52|   6.17|                      14|\n",
      "|  13.06|   5.31|                      14|\n",
      "|   6.19|   8.03|                      14|\n",
      "|   7.54|   4.49|                      14|\n",
      "+-------+-------+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "query3 = \"\"\"\n",
    "SELECT\n",
    "    FLOOR(a.Latitude * 100) / 100 AS lat_bin,\n",
    "    FLOOR(a.Longitude * 100) / 100 AS lon_bin,\n",
    "    COUNT(*) AS nb_accidents_dans_buffer\n",
    "FROM accidents a\n",
    "GROUP BY lat_bin, lon_bin\n",
    "ORDER BY nb_accidents_dans_buffer DESC\n",
    "LIMIT 10\n",
    "\"\"\"\n",
    "\n",
    "result3 = spark.sql(query3)\n",
    "result3.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
